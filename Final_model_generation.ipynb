{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('final_covariates_Data.csv')\n",
    "article_data = pd.read_csv(\"top5_articlesday.csv\")\n",
    "\n",
    "article_data = article_data.groupby(['date'], as_index = False).agg({\"headline_sentiment\": \"mean\", \"paragraph_sentiment\": \"mean\", \"relevance\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"DATE\"] = pd.to_datetime(all_data[\"DATE\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Moody's Seasoned Aaa Corporate Bond Yield Relative to Yield on 10-Year</th>\n",
       "      <th>Moody's Seasoned Aaa Corporate Bond Minus Federal Funds Rate</th>\n",
       "      <th>Moody's Seasoned Baa Corporate Bond Yield Relative to Yield on 10-Year</th>\n",
       "      <th>Moody's Seasoned Baa Corporate Bond Minus Federal Funds Rate</th>\n",
       "      <th>ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread</th>\n",
       "      <th>ICE BofA High Yield Emerging Markets Corporate Plus Index Effective Yield</th>\n",
       "      <th>ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread</th>\n",
       "      <th>3-Month Commercial Paper Minus Federal Funds Rate</th>\n",
       "      <th>Moody's Seasoned Aaa Corporate Bond Yield</th>\n",
       "      <th>...</th>\n",
       "      <th>ICE BofA Euro High Yield Index Option-Adjusted Spread</th>\n",
       "      <th>ICE BofA US High Yield Index Total Return Index Value</th>\n",
       "      <th>NASDAQ 100 Index</th>\n",
       "      <th>NASDAQ Composite Index</th>\n",
       "      <th>Nikkei Stock Average, Nikkei 225</th>\n",
       "      <th>CBOE Volatility Index: VIX</th>\n",
       "      <th>Wilshire 5000 Total Market Index</th>\n",
       "      <th>Wilshire 5000 Total Market Full Cap Index</th>\n",
       "      <th>Wilshire 5000 Price Index</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2341.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.24</td>\n",
       "      <td>5.60</td>\n",
       "      <td>13.37</td>\n",
       "      <td>8.44</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>7.08</td>\n",
       "      <td>...</td>\n",
       "      <td>11.68</td>\n",
       "      <td>346.15</td>\n",
       "      <td>2128.78</td>\n",
       "      <td>2291.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.99</td>\n",
       "      <td>38.46</td>\n",
       "      <td>38.46</td>\n",
       "      <td>11763.92</td>\n",
       "      <td>11763.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.83</td>\n",
       "      <td>1.62</td>\n",
       "      <td>5.53</td>\n",
       "      <td>13.35</td>\n",
       "      <td>8.30</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>7.11</td>\n",
       "      <td>...</td>\n",
       "      <td>11.68</td>\n",
       "      <td>346.77</td>\n",
       "      <td>2528.38</td>\n",
       "      <td>2616.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.60</td>\n",
       "      <td>40.48</td>\n",
       "      <td>40.48</td>\n",
       "      <td>12380.26</td>\n",
       "      <td>12380.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.02</td>\n",
       "      <td>5.53</td>\n",
       "      <td>13.26</td>\n",
       "      <td>8.30</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>7.09</td>\n",
       "      <td>...</td>\n",
       "      <td>11.40</td>\n",
       "      <td>348.81</td>\n",
       "      <td>2460.04</td>\n",
       "      <td>2566.83</td>\n",
       "      <td>13691.49</td>\n",
       "      <td>26.97</td>\n",
       "      <td>39.97</td>\n",
       "      <td>39.97</td>\n",
       "      <td>12224.42</td>\n",
       "      <td>12224.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.09</td>\n",
       "      <td>5.57</td>\n",
       "      <td>13.23</td>\n",
       "      <td>8.40</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>7.08</td>\n",
       "      <td>...</td>\n",
       "      <td>11.44</td>\n",
       "      <td>350.67</td>\n",
       "      <td>2267.85</td>\n",
       "      <td>2407.65</td>\n",
       "      <td>13867.61</td>\n",
       "      <td>28.67</td>\n",
       "      <td>38.82</td>\n",
       "      <td>38.82</td>\n",
       "      <td>11872.66</td>\n",
       "      <td>11872.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8125 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE  \\\n",
       "0     2001-01-01   \n",
       "1     2001-01-02   \n",
       "2     2001-01-03   \n",
       "3     2001-01-04   \n",
       "4     2001-01-05   \n",
       "...          ...   \n",
       "8120         NaN   \n",
       "8121         NaN   \n",
       "8122         NaN   \n",
       "8123         NaN   \n",
       "8124         NaN   \n",
       "\n",
       "      Moody's Seasoned Aaa Corporate Bond Yield Relative to Yield on 10-Year  \\\n",
       "0                                                   NaN                        \n",
       "1                                                  2.16                        \n",
       "2                                                  1.97                        \n",
       "3                                                  2.06                        \n",
       "4                                                  2.15                        \n",
       "...                                                 ...                        \n",
       "8120                                                NaN                        \n",
       "8121                                                NaN                        \n",
       "8122                                                NaN                        \n",
       "8123                                                NaN                        \n",
       "8124                                                NaN                        \n",
       "\n",
       "      Moody's Seasoned Aaa Corporate Bond Minus Federal Funds Rate  \\\n",
       "0                                                   NaN              \n",
       "1                                                  0.41              \n",
       "2                                                  0.76              \n",
       "3                                                  1.17              \n",
       "4                                                  1.25              \n",
       "...                                                 ...              \n",
       "8120                                                NaN              \n",
       "8121                                                NaN              \n",
       "8122                                                NaN              \n",
       "8123                                                NaN              \n",
       "8124                                                NaN              \n",
       "\n",
       "      Moody's Seasoned Baa Corporate Bond Yield Relative to Yield on 10-Year  \\\n",
       "0                                                   NaN                        \n",
       "1                                                  2.99                        \n",
       "2                                                  2.83                        \n",
       "3                                                  2.91                        \n",
       "4                                                  2.99                        \n",
       "...                                                 ...                        \n",
       "8120                                                NaN                        \n",
       "8121                                                NaN                        \n",
       "8122                                                NaN                        \n",
       "8123                                                NaN                        \n",
       "8124                                                NaN                        \n",
       "\n",
       "      Moody's Seasoned Baa Corporate Bond Minus Federal Funds Rate  \\\n",
       "0                                                   NaN              \n",
       "1                                                  1.24              \n",
       "2                                                  1.62              \n",
       "3                                                  2.02              \n",
       "4                                                  2.09              \n",
       "...                                                 ...              \n",
       "8120                                                NaN              \n",
       "8121                                                NaN              \n",
       "8122                                                NaN              \n",
       "8123                                                NaN              \n",
       "8124                                                NaN              \n",
       "\n",
       "      ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread  \\\n",
       "0                                                   NaN                       \n",
       "1                                                  5.60                       \n",
       "2                                                  5.53                       \n",
       "3                                                  5.53                       \n",
       "4                                                  5.57                       \n",
       "...                                                 ...                       \n",
       "8120                                                NaN                       \n",
       "8121                                                NaN                       \n",
       "8122                                                NaN                       \n",
       "8123                                                NaN                       \n",
       "8124                                                NaN                       \n",
       "\n",
       "      ICE BofA High Yield Emerging Markets Corporate Plus Index Effective Yield  \\\n",
       "0                                                   NaN                           \n",
       "1                                                 13.37                           \n",
       "2                                                 13.35                           \n",
       "3                                                 13.26                           \n",
       "4                                                 13.23                           \n",
       "...                                                 ...                           \n",
       "8120                                                NaN                           \n",
       "8121                                                NaN                           \n",
       "8122                                                NaN                           \n",
       "8123                                                NaN                           \n",
       "8124                                                NaN                           \n",
       "\n",
       "      ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread  \\\n",
       "0                                                   NaN                                  \n",
       "1                                                  8.44                                  \n",
       "2                                                  8.30                                  \n",
       "3                                                  8.30                                  \n",
       "4                                                  8.40                                  \n",
       "...                                                 ...                                  \n",
       "8120                                                NaN                                  \n",
       "8121                                                NaN                                  \n",
       "8122                                                NaN                                  \n",
       "8123                                                NaN                                  \n",
       "8124                                                NaN                                  \n",
       "\n",
       "      3-Month Commercial Paper Minus Federal Funds Rate  \\\n",
       "0                                                   NaN   \n",
       "1                                                 -0.53   \n",
       "2                                                 -0.30   \n",
       "3                                                 -0.21   \n",
       "4                                                 -0.37   \n",
       "...                                                 ...   \n",
       "8120                                                NaN   \n",
       "8121                                                NaN   \n",
       "8122                                                NaN   \n",
       "8123                                                NaN   \n",
       "8124                                                NaN   \n",
       "\n",
       "      Moody's Seasoned Aaa Corporate Bond Yield  ...  \\\n",
       "0                                           NaN  ...   \n",
       "1                                          7.08  ...   \n",
       "2                                          7.11  ...   \n",
       "3                                          7.09  ...   \n",
       "4                                          7.08  ...   \n",
       "...                                         ...  ...   \n",
       "8120                                        NaN  ...   \n",
       "8121                                        NaN  ...   \n",
       "8122                                        NaN  ...   \n",
       "8123                                        NaN  ...   \n",
       "8124                                        NaN  ...   \n",
       "\n",
       "      ICE BofA Euro High Yield Index Option-Adjusted Spread  \\\n",
       "0                                                   NaN       \n",
       "1                                                 11.68       \n",
       "2                                                 11.68       \n",
       "3                                                 11.40       \n",
       "4                                                 11.44       \n",
       "...                                                 ...       \n",
       "8120                                                NaN       \n",
       "8121                                                NaN       \n",
       "8122                                                NaN       \n",
       "8123                                                NaN       \n",
       "8124                                                NaN       \n",
       "\n",
       "      ICE BofA US High Yield Index Total Return Index Value  NASDAQ 100 Index  \\\n",
       "0                                                   NaN               2341.70   \n",
       "1                                                346.15               2128.78   \n",
       "2                                                346.77               2528.38   \n",
       "3                                                348.81               2460.04   \n",
       "4                                                350.67               2267.85   \n",
       "...                                                 ...                   ...   \n",
       "8120                                                NaN                   NaN   \n",
       "8121                                                NaN                   NaN   \n",
       "8122                                                NaN                   NaN   \n",
       "8123                                                NaN                   NaN   \n",
       "8124                                                NaN                   NaN   \n",
       "\n",
       "      NASDAQ Composite Index  Nikkei Stock Average, Nikkei 225  \\\n",
       "0                        NaN                               NaN   \n",
       "1                    2291.86                               NaN   \n",
       "2                    2616.69                               NaN   \n",
       "3                    2566.83                          13691.49   \n",
       "4                    2407.65                          13867.61   \n",
       "...                      ...                               ...   \n",
       "8120                     NaN                               NaN   \n",
       "8121                     NaN                               NaN   \n",
       "8122                     NaN                               NaN   \n",
       "8123                     NaN                               NaN   \n",
       "8124                     NaN                               NaN   \n",
       "\n",
       "      CBOE Volatility Index: VIX  Wilshire 5000 Total Market Index  \\\n",
       "0                            NaN                               NaN   \n",
       "1                          29.99                             38.46   \n",
       "2                          26.60                             40.48   \n",
       "3                          26.97                             39.97   \n",
       "4                          28.67                             38.82   \n",
       "...                          ...                               ...   \n",
       "8120                         NaN                               NaN   \n",
       "8121                         NaN                               NaN   \n",
       "8122                         NaN                               NaN   \n",
       "8123                         NaN                               NaN   \n",
       "8124                         NaN                               NaN   \n",
       "\n",
       "      Wilshire 5000 Total Market Full Cap Index  Wilshire 5000 Price Index  \\\n",
       "0                                           NaN                        NaN   \n",
       "1                                         38.46                   11763.92   \n",
       "2                                         40.48                   12380.26   \n",
       "3                                         39.97                   12224.42   \n",
       "4                                         38.82                   11872.66   \n",
       "...                                         ...                        ...   \n",
       "8120                                        NaN                        NaN   \n",
       "8121                                        NaN                        NaN   \n",
       "8122                                        NaN                        NaN   \n",
       "8123                                        NaN                        NaN   \n",
       "8124                                        NaN                        NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index  \n",
       "0                                    NaN  \n",
       "1                               11763.92  \n",
       "2                               12380.26  \n",
       "3                               12224.42  \n",
       "4                               11872.66  \n",
       "...                                  ...  \n",
       "8120                                 NaN  \n",
       "8121                                 NaN  \n",
       "8122                                 NaN  \n",
       "8123                                 NaN  \n",
       "8124                                 NaN  \n",
       "\n",
       "[8125 rows x 115 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data[\"date\"] = pd.to_datetime(article_data[\"date\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = article_data.merge(all_data, how = 'left',  right_on= 'DATE', left_on = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'headline_sentiment',\n",
       " 'paragraph_sentiment',\n",
       " 'relevance',\n",
       " 'DATE',\n",
       " \"Moody's Seasoned Aaa Corporate Bond Yield Relative to Yield on 10-Year\",\n",
       " \"Moody's Seasoned Aaa Corporate Bond Minus Federal Funds Rate\",\n",
       " \"Moody's Seasoned Baa Corporate Bond Yield Relative to Yield on 10-Year\",\n",
       " \"Moody's Seasoned Baa Corporate Bond Minus Federal Funds Rate\",\n",
       " 'ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread',\n",
       " 'ICE BofA High Yield Emerging Markets Corporate Plus Index Effective Yield',\n",
       " 'ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread',\n",
       " '3-Month Commercial Paper Minus Federal Funds Rate',\n",
       " \"Moody's Seasoned Aaa Corporate Bond Yield\",\n",
       " \"Moody's Seasoned Baa Corporate Bond Yield\",\n",
       " 'Crude Oil Prices: Brent - Europe',\n",
       " 'Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate',\n",
       " 'Brazilian Reals to U.S. Dollar Spot Exchange Rate',\n",
       " 'Canadian Dollars to U.S. Dollar Spot Exchange Rate',\n",
       " 'Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate',\n",
       " 'Indian Rupees to U.S. Dollar Spot Exchange Rate',\n",
       " 'Japanese Yen to U.S. Dollar Spot Exchange Rate',\n",
       " 'South Korean Won to U.S. Dollar Spot Exchange Rate',\n",
       " 'Malaysian Ringgit to U.S. Dollar Spot Exchange Rate',\n",
       " 'Mexican Pesos to U.S. Dollar Spot Exchange Rate',\n",
       " 'South African Rand to U.S. Dollar Spot Exchange Rate',\n",
       " 'Sri Lankan Rupees to U.S. Dollar Spot Exchange Rate',\n",
       " 'Swiss Francs to U.S. Dollar Spot Exchange Rate',\n",
       " 'Thai Baht to U.S. Dollar Spot Exchange Rate',\n",
       " 'U.S. Dollars to Australian Dollar Spot Exchange Rate',\n",
       " 'U.S. Dollars to Euro Spot Exchange Rate',\n",
       " 'U.S. Dollars to U.K. Pound Sterling Spot Exchange Rate',\n",
       " 'Venezuelan Bolivares to U.S. Dollar Spot Exchange Rate',\n",
       " 'Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed',\n",
       " 'Market Yield on U.S. Treasury Securities at 5-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed',\n",
       " 'Market Yield on U.S. Treasury Securities at 1-Year Constant Maturity, quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 1-Month Constant Maturity quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 2-Year Constant Maturity Quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 20-Year Constant Maturity Quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 3-Year Constant Maturity Quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 30-Year Constant Maturity Quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 3-Month Constant Maturity Quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 5-Year Constant Maturity Quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 6-Month Constant Maturity Quoted on an Investment Basis',\n",
       " 'Market Yield on U.S. Treasury Securities at 7-Year Constant Maturity Quoted on an Investment Basis',\n",
       " 'Henry Hub Natural Gas Spot Price',\n",
       " 'Kerosene-Type Jet Fuel Prices: U.S. Gulf Coast',\n",
       " 'Treasury Long-Term Average (Over 10 Years), Inflation-Indexed',\n",
       " 'Discount Window Primary Credit Rate',\n",
       " 'Bank Prime Loan Rate',\n",
       " '1-Year Treasury Bill Secondary Market Rate, Discount Basis',\n",
       " '3-Month Treasury Bill Secondary Market Rate, Discount Basis',\n",
       " '4-Week Treasury Bill Secondary Market Rate, Discount Basis',\n",
       " '6-Month Treasury Bill Secondary Market Rate, Discount Basis',\n",
       " 'Effective Federal Funds Rate',\n",
       " 'Daily Sterling Overnight Index Average (SONIA) Rate',\n",
       " 'Federal Funds Effective Rate',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate.1',\n",
       " '90-Day A2/P2 Nonfinancial Commercial Paper Interest Rate',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate.1',\n",
       " 'Overnight Repurchase Agreements: Treasury Securities Purchased by the Federal Reserve in the Temporary Open Market Operations',\n",
       " 'Overnight Repurchase Agreements: Total Securities Purchased by the Federal Reserve in the Temporary Open Market Operations',\n",
       " 'Overnight Reverse Repurchase Agreements Award Rate: Treasury Securities Sold by the Federal Reserve in the Temporary Open Market Operations',\n",
       " 'Overnight Reverse Repurchase Agreements: Treasury Securities Sold by the Federal Reserve in the Temporary Open Market Operations',\n",
       " 'Overnight Reverse Repurchase Agreements: Total Securities Sold by the Federal Reserve in the Temporary Open Market Operations ',\n",
       " '10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity',\n",
       " '10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity',\n",
       " '10-Year Treasury Constant Maturity Minus Federal Funds Rate',\n",
       " '10-Year Breakeven Inflation Rate',\n",
       " '1-Year Treasury Constant Maturity Minus Federal Funds Rate',\n",
       " '3-Month Treasury Constant Maturity Minus Federal Funds Rate',\n",
       " '5-Year Treasury Constant Maturity Minus Federal Funds Rate',\n",
       " '5-Year Breakeven Inflation Rate',\n",
       " '5-Year, 5-Year Forward Inflation Expectation Rate',\n",
       " 'Fitted Instantaneous Forward Rate 2 Years Hence',\n",
       " 'Fitted Yield on a 10 Year Zero Coupon Bond',\n",
       " 'Federal Funds Effective Rate.1',\n",
       " 'ECBDFR',\n",
       " 'Board of Governors of the Federal Reserve System (US)',\n",
       " 'Discount Window Primary Credit Rate.1',\n",
       " 'Economic Policy Uncertainty Index for United States',\n",
       " 'NBER based Recession Indicators for the United States from the Period following the Peak through the Trough',\n",
       " 'NBER based Recession Indicators for the United States from the Peak through the Trough',\n",
       " 'ICE BofA US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA US Corporate Index Effective Yield',\n",
       " 'ICE BofA AAA US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA AAA US Corporate Index Effective Yield',\n",
       " 'ICE BofA AA US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA AA US Corporate Index Effective Yield',\n",
       " 'ICE BofA Single-A US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA Single-A US Corporate Index Effective Yield',\n",
       " 'ICE BofA BBB US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA BBB US Corporate Index Effective Yield',\n",
       " 'ICE BofA 1-3 Year US Corporate Index Effective Yield',\n",
       " 'ICE BofA 7-10 Year US Corporate Index Effective Yield',\n",
       " 'ICE BofA US Corporate Index Total Return Index Value',\n",
       " 'ICE BofA US High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA US High Yield Index Effective Yield',\n",
       " 'ICE BofA US High Yield Index Semi-Annual Yield to Worst',\n",
       " 'ICE BofA BB US High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA BB US High Yield Index Effective Yield',\n",
       " 'ICE BofA Single-B US High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA Single-B US High Yield Index Effective Yield',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Effective Yield',\n",
       " 'ICE BofA Euro High Yield Index Effective Yield',\n",
       " 'ICE BofA Euro High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA US High Yield Index Total Return Index Value',\n",
       " 'NASDAQ 100 Index',\n",
       " 'NASDAQ Composite Index',\n",
       " 'Nikkei Stock Average, Nikkei 225',\n",
       " 'CBOE Volatility Index: VIX',\n",
       " 'Wilshire 5000 Total Market Index',\n",
       " 'Wilshire 5000 Total Market Full Cap Index',\n",
       " 'Wilshire 5000 Price Index',\n",
       " 'Wilshire 5000 Full Cap Price Index']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2001-01-01\n",
       "1       2001-01-02\n",
       "2       2001-01-03\n",
       "3       2001-01-04\n",
       "4       2001-01-05\n",
       "           ...    \n",
       "8036           NaN\n",
       "8037    2023-03-27\n",
       "8038    2023-03-28\n",
       "8039    2023-03-29\n",
       "8040    2023-03-30\n",
       "Name: DATE, Length: 8041, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"DATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.drop(['South African Rand to U.S. Dollar Spot Exchange Rate',\n",
    " 'Sri Lankan Rupees to U.S. Dollar Spot Exchange Rate',\n",
    " 'Swiss Francs to U.S. Dollar Spot Exchange Rate',\n",
    " 'Thai Baht to U.S. Dollar Spot Exchange Rate',\n",
    " 'U.S. Dollars to Australian Dollar Spot Exchange Rate',\n",
    " 'U.S. Dollars to Euro Spot Exchange Rate',\n",
    " 'U.S. Dollars to U.K. Pound Sterling Spot Exchange Rate',\n",
    " 'Venezuelan Bolivares to U.S. Dollar Spot Exchange Rate', \n",
    "  'Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity quoted on an Investment Basis',\n",
    " 'Market Yield on U.S. Treasury Securities at 1-Month Constant Maturity quoted on an Investment Basis',\n",
    " 'Market Yield on U.S. Treasury Securities at 2-Year Constant Maturity Quoted on an Investment Basis',\n",
    " 'Market Yield on U.S. Treasury Securities at 20-Year Constant Maturity Quoted on an Investment Basis',\n",
    " 'Market Yield on U.S. Treasury Securities at 3-Year Constant Maturity Quoted on an Investment Basis',\n",
    " 'Market Yield on U.S. Treasury Securities at 30-Year Constant Maturity Quoted on an Investment Basis',\n",
    " 'Market Yield on U.S. Treasury Securities at 3-Month Constant Maturity Quoted on an Investment Basis',\n",
    " 'Market Yield on U.S. Treasury Securities at 5-Year Constant Maturity Quoted on an Investment Basis',\n",
    " 'Market Yield on U.S. Treasury Securities at 6-Month Constant Maturity Quoted on an Investment Basis',\n",
    " 'Market Yield on U.S. Treasury Securities at 7-Year Constant Maturity Quoted on an Investment Basis',\n",
    "  'DATE',\n",
    "   'ICE BofA High Yield Emerging Markets Corporate Plus Index Effective Yield',\n",
    "    \"Moody's Seasoned Aaa Corporate Bond Yield Relative to Yield on 10-Year\",\n",
    " \"Moody's Seasoned Aaa Corporate Bond Minus Federal Funds Rate\",\n",
    " \"Moody's Seasoned Baa Corporate Bond Yield Relative to Yield on 10-Year\",\n",
    " \"Moody's Seasoned Baa Corporate Bond Minus Federal Funds Rate\",\n",
    "  '1-Year Treasury Constant Maturity Minus Federal Funds Rate',\n",
    " '3-Month Treasury Constant Maturity Minus Federal Funds Rate',\n",
    " '5-Year Treasury Constant Maturity Minus Federal Funds Rate', \n",
    "  'Overnight Reverse Repurchase Agreements Award Rate: Treasury Securities Sold by the Federal Reserve in the Temporary Open Market Operations',\n",
    " 'Overnight Reverse Repurchase Agreements: Treasury Securities Sold by the Federal Reserve in the Temporary Open Market Operations',\n",
    " 'Overnight Reverse Repurchase Agreements: Total Securities Sold by the Federal Reserve in the Temporary Open Market Operations ',\n",
    "  'Overnight Repurchase Agreements: Treasury Securities Purchased by the Federal Reserve in the Temporary Open Market Operations',\n",
    "  ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3838456948.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[i + \" lag_6\"] = x_data[i].shift(6)\n"
     ]
    }
   ],
   "source": [
    "list_of_cols = x_data.columns.tolist()\n",
    "for i in list_of_cols[1:]:\n",
    "    x_data[i + \" lag_1\"] = x_data[i].shift(1)\n",
    "    x_data[i + \" lag_2\"] = x_data[i].shift(2)\n",
    "    x_data[i + \" lag_3\"] = x_data[i].shift(3)\n",
    "    x_data[i + \" lag_4\"] = x_data[i].shift(4)\n",
    "    x_data[i + \" lag_5\"] = x_data[i].shift(5)\n",
    "    x_data[i + \" lag_6\"] = x_data[i].shift(6)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline_sentiment</th>\n",
       "      <th>paragraph_sentiment</th>\n",
       "      <th>relevance</th>\n",
       "      <th>ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread</th>\n",
       "      <th>ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread</th>\n",
       "      <th>3-Month Commercial Paper Minus Federal Funds Rate</th>\n",
       "      <th>Moody's Seasoned Aaa Corporate Bond Yield</th>\n",
       "      <th>Moody's Seasoned Baa Corporate Bond Yield</th>\n",
       "      <th>Crude Oil Prices: Brent - Europe</th>\n",
       "      <th>...</th>\n",
       "      <th>Wilshire 5000 Price Index lag_3</th>\n",
       "      <th>Wilshire 5000 Price Index lag_4</th>\n",
       "      <th>Wilshire 5000 Price Index lag_5</th>\n",
       "      <th>Wilshire 5000 Price Index lag_6</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_1</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_2</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_3</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_4</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_5</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>-0.06328</td>\n",
       "      <td>-0.14274</td>\n",
       "      <td>0.927433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>-0.19948</td>\n",
       "      <td>0.23176</td>\n",
       "      <td>0.763274</td>\n",
       "      <td>5.60</td>\n",
       "      <td>8.44</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.91</td>\n",
       "      <td>23.43</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>0.04526</td>\n",
       "      <td>-0.01032</td>\n",
       "      <td>0.926602</td>\n",
       "      <td>5.53</td>\n",
       "      <td>8.30</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>7.11</td>\n",
       "      <td>7.97</td>\n",
       "      <td>23.44</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11763.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>-0.11490</td>\n",
       "      <td>-0.06654</td>\n",
       "      <td>0.814249</td>\n",
       "      <td>5.53</td>\n",
       "      <td>8.30</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.94</td>\n",
       "      <td>24.57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12380.26</td>\n",
       "      <td>11763.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.19282</td>\n",
       "      <td>0.752776</td>\n",
       "      <td>5.57</td>\n",
       "      <td>8.40</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.92</td>\n",
       "      <td>24.77</td>\n",
       "      <td>...</td>\n",
       "      <td>11763.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12224.42</td>\n",
       "      <td>12380.26</td>\n",
       "      <td>11763.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>-0.11548</td>\n",
       "      <td>0.06818</td>\n",
       "      <td>0.874832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40921.86</td>\n",
       "      <td>40709.45</td>\n",
       "      <td>40136.22</td>\n",
       "      <td>40189.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40708.47</td>\n",
       "      <td>40086.96</td>\n",
       "      <td>39880.56</td>\n",
       "      <td>39318.14</td>\n",
       "      <td>39374.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8037</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.06438</td>\n",
       "      <td>0.749614</td>\n",
       "      <td>3.12</td>\n",
       "      <td>6.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.54</td>\n",
       "      <td>5.72</td>\n",
       "      <td>76.80</td>\n",
       "      <td>...</td>\n",
       "      <td>41548.10</td>\n",
       "      <td>40921.86</td>\n",
       "      <td>40709.45</td>\n",
       "      <td>40136.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40708.47</td>\n",
       "      <td>40086.96</td>\n",
       "      <td>39880.56</td>\n",
       "      <td>39318.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>0.18448</td>\n",
       "      <td>0.04176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.13</td>\n",
       "      <td>6.93</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.51</td>\n",
       "      <td>5.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41548.10</td>\n",
       "      <td>40921.86</td>\n",
       "      <td>40709.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40708.47</td>\n",
       "      <td>40086.96</td>\n",
       "      <td>39880.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8039</th>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>0.03512</td>\n",
       "      <td>0.27466</td>\n",
       "      <td>0.947215</td>\n",
       "      <td>3.08</td>\n",
       "      <td>6.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41548.10</td>\n",
       "      <td>40921.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40708.47</td>\n",
       "      <td>40086.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8040</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>-0.08726</td>\n",
       "      <td>-0.17598</td>\n",
       "      <td>0.941916</td>\n",
       "      <td>3.04</td>\n",
       "      <td>6.70</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41548.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40708.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8041 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  headline_sentiment  paragraph_sentiment  relevance  \\\n",
       "0     2001-01-01            -0.06328             -0.14274   0.927433   \n",
       "1     2001-01-02            -0.19948              0.23176   0.763274   \n",
       "2     2001-01-03             0.04526             -0.01032   0.926602   \n",
       "3     2001-01-04            -0.11490             -0.06654   0.814249   \n",
       "4     2001-01-05             0.03950              0.19282   0.752776   \n",
       "...          ...                 ...                  ...        ...   \n",
       "8036  2023-03-26            -0.11548              0.06818   0.874832   \n",
       "8037  2023-03-27             0.01308              0.06438   0.749614   \n",
       "8038  2023-03-28             0.18448              0.04176   1.000000   \n",
       "8039  2023-03-29             0.03512              0.27466   0.947215   \n",
       "8040  2023-03-30            -0.08726             -0.17598   0.941916   \n",
       "\n",
       "      ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread  \\\n",
       "0                                                   NaN                       \n",
       "1                                                  5.60                       \n",
       "2                                                  5.53                       \n",
       "3                                                  5.53                       \n",
       "4                                                  5.57                       \n",
       "...                                                 ...                       \n",
       "8036                                                NaN                       \n",
       "8037                                               3.12                       \n",
       "8038                                               3.13                       \n",
       "8039                                               3.08                       \n",
       "8040                                               3.04                       \n",
       "\n",
       "      ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread  \\\n",
       "0                                                   NaN                                  \n",
       "1                                                  8.44                                  \n",
       "2                                                  8.30                                  \n",
       "3                                                  8.30                                  \n",
       "4                                                  8.40                                  \n",
       "...                                                 ...                                  \n",
       "8036                                                NaN                                  \n",
       "8037                                               6.96                                  \n",
       "8038                                               6.93                                  \n",
       "8039                                               6.80                                  \n",
       "8040                                               6.70                                  \n",
       "\n",
       "      3-Month Commercial Paper Minus Federal Funds Rate  \\\n",
       "0                                                   NaN   \n",
       "1                                                 -0.53   \n",
       "2                                                 -0.30   \n",
       "3                                                 -0.21   \n",
       "4                                                 -0.37   \n",
       "...                                                 ...   \n",
       "8036                                                NaN   \n",
       "8037                                                NaN   \n",
       "8038                                               0.04   \n",
       "8039                                                NaN   \n",
       "8040                                               0.22   \n",
       "\n",
       "      Moody's Seasoned Aaa Corporate Bond Yield  \\\n",
       "0                                           NaN   \n",
       "1                                          7.08   \n",
       "2                                          7.11   \n",
       "3                                          7.09   \n",
       "4                                          7.08   \n",
       "...                                         ...   \n",
       "8036                                        NaN   \n",
       "8037                                       4.54   \n",
       "8038                                       4.51   \n",
       "8039                                       4.52   \n",
       "8040                                       4.48   \n",
       "\n",
       "      Moody's Seasoned Baa Corporate Bond Yield  \\\n",
       "0                                           NaN   \n",
       "1                                          7.91   \n",
       "2                                          7.97   \n",
       "3                                          7.94   \n",
       "4                                          7.92   \n",
       "...                                         ...   \n",
       "8036                                        NaN   \n",
       "8037                                       5.72   \n",
       "8038                                       5.74   \n",
       "8039                                       5.72   \n",
       "8040                                       5.66   \n",
       "\n",
       "      Crude Oil Prices: Brent - Europe  ...  Wilshire 5000 Price Index lag_3  \\\n",
       "0                                  NaN  ...                              NaN   \n",
       "1                                23.43  ...                              NaN   \n",
       "2                                23.44  ...                              NaN   \n",
       "3                                24.57  ...                              NaN   \n",
       "4                                24.77  ...                         11763.92   \n",
       "...                                ...  ...                              ...   \n",
       "8036                               NaN  ...                         40921.86   \n",
       "8037                             76.80  ...                         41548.10   \n",
       "8038                               NaN  ...                              NaN   \n",
       "8039                               NaN  ...                              NaN   \n",
       "8040                               NaN  ...                              NaN   \n",
       "\n",
       "      Wilshire 5000 Price Index lag_4  Wilshire 5000 Price Index lag_5  \\\n",
       "0                                 NaN                              NaN   \n",
       "1                                 NaN                              NaN   \n",
       "2                                 NaN                              NaN   \n",
       "3                                 NaN                              NaN   \n",
       "4                                 NaN                              NaN   \n",
       "...                               ...                              ...   \n",
       "8036                         40709.45                         40136.22   \n",
       "8037                         40921.86                         40709.45   \n",
       "8038                         41548.10                         40921.86   \n",
       "8039                              NaN                         41548.10   \n",
       "8040                              NaN                              NaN   \n",
       "\n",
       "      Wilshire 5000 Price Index lag_6  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2                                 NaN   \n",
       "3                                 NaN   \n",
       "4                                 NaN   \n",
       "...                               ...   \n",
       "8036                         40189.93   \n",
       "8037                         40136.22   \n",
       "8038                         40709.45   \n",
       "8039                         40921.86   \n",
       "8040                         41548.10   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_1  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                     11763.92   \n",
       "3                                     12380.26   \n",
       "4                                     12224.42   \n",
       "...                                        ...   \n",
       "8036                                       NaN   \n",
       "8037                                       NaN   \n",
       "8038                                       NaN   \n",
       "8039                                       NaN   \n",
       "8040                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_2  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                     11763.92   \n",
       "4                                     12380.26   \n",
       "...                                        ...   \n",
       "8036                                  40708.47   \n",
       "8037                                       NaN   \n",
       "8038                                       NaN   \n",
       "8039                                       NaN   \n",
       "8040                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_3  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                     11763.92   \n",
       "...                                        ...   \n",
       "8036                                  40086.96   \n",
       "8037                                  40708.47   \n",
       "8038                                       NaN   \n",
       "8039                                       NaN   \n",
       "8040                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_4  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "...                                        ...   \n",
       "8036                                  39880.56   \n",
       "8037                                  40086.96   \n",
       "8038                                  40708.47   \n",
       "8039                                       NaN   \n",
       "8040                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_5  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "...                                        ...   \n",
       "8036                                  39318.14   \n",
       "8037                                  39880.56   \n",
       "8038                                  40086.96   \n",
       "8039                                  40708.47   \n",
       "8040                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_6  \n",
       "0                                          NaN  \n",
       "1                                          NaN  \n",
       "2                                          NaN  \n",
       "3                                          NaN  \n",
       "4                                          NaN  \n",
       "...                                        ...  \n",
       "8036                                  39374.94  \n",
       "8037                                  39318.14  \n",
       "8038                                  39880.56  \n",
       "8039                                  40086.96  \n",
       "8040                                  40708.47  \n",
       "\n",
       "[8041 rows x 610 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv(\"sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data.drop(['Unnamed: 6', 'Unnamed: 7', \"Bull-Bear Spread\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3905100921.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_data[\"Reported Date\"] = pd.to_datetime(y_data[\"Reported Date\"], infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "y_data[\"Reported Date\"] = pd.to_datetime(y_data[\"Reported Date\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\3731391445.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_data[\"data\"] = pd.to_datetime(x_data[\"date\"], infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "x_data[\"data\"] = pd.to_datetime(x_data[\"date\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2001-01-01\n",
       "1      2001-01-02\n",
       "2      2001-01-03\n",
       "3      2001-01-04\n",
       "4      2001-01-05\n",
       "          ...    \n",
       "8036   2023-03-26\n",
       "8037   2023-03-27\n",
       "8038   2023-03-28\n",
       "8039   2023-03-29\n",
       "8040   2023-03-30\n",
       "Name: data, Length: 8041, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2001-01-04\n",
       "1      2001-01-11\n",
       "2      2001-01-18\n",
       "3      2001-01-25\n",
       "4      2001-02-01\n",
       "          ...    \n",
       "1155   2023-03-02\n",
       "1156   2023-03-09\n",
       "1157   2023-03-16\n",
       "1158   2023-03-23\n",
       "1159   2023-03-30\n",
       "Name: Reported Date, Length: 1160, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[\"Reported Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = y_data.join(x_data.set_index('data'), on='Reported Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(df):\n",
    "    list_of_beliefs = [df[\"Bullish\"], df[\"Neutral\"], df[\"Bearish\"]]\n",
    "    if list_of_beliefs.index(max(list_of_beliefs)) == 0:\n",
    "        return \"Bullish\"\n",
    "    elif list_of_beliefs.index(max(list_of_beliefs)) == 1:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bearish\"\n",
    "    \n",
    "final_data[\"Sentiment\"] = final_data.apply(test_function, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.drop([\"Bullish\", \"Neutral\", \"Bearish\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reported Date</th>\n",
       "      <th>S&amp;P 500 Weekly Close</th>\n",
       "      <th>date</th>\n",
       "      <th>headline_sentiment</th>\n",
       "      <th>paragraph_sentiment</th>\n",
       "      <th>relevance</th>\n",
       "      <th>ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread</th>\n",
       "      <th>ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread</th>\n",
       "      <th>3-Month Commercial Paper Minus Federal Funds Rate</th>\n",
       "      <th>Moody's Seasoned Aaa Corporate Bond Yield</th>\n",
       "      <th>...</th>\n",
       "      <th>Wilshire 5000 Price Index lag_4</th>\n",
       "      <th>Wilshire 5000 Price Index lag_5</th>\n",
       "      <th>Wilshire 5000 Price Index lag_6</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_1</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_2</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_3</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_4</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_5</th>\n",
       "      <th>Wilshire 5000 Full Cap Price Index lag_6</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>1,320.28</td>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>-0.11490</td>\n",
       "      <td>-0.06654</td>\n",
       "      <td>0.814249</td>\n",
       "      <td>5.53</td>\n",
       "      <td>8.30</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>7.09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12380.26</td>\n",
       "      <td>11763.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-11</td>\n",
       "      <td>1,298.35</td>\n",
       "      <td>2001-01-11</td>\n",
       "      <td>0.20524</td>\n",
       "      <td>0.00962</td>\n",
       "      <td>0.867437</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.09</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>7.17</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11872.66</td>\n",
       "      <td>12064.50</td>\n",
       "      <td>11896.98</td>\n",
       "      <td>11836.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11872.66</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-18</td>\n",
       "      <td>1,318.55</td>\n",
       "      <td>2001-01-18</td>\n",
       "      <td>-0.12708</td>\n",
       "      <td>0.03530</td>\n",
       "      <td>0.938922</td>\n",
       "      <td>5.39</td>\n",
       "      <td>8.03</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>7.09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12181.33</td>\n",
       "      <td>12310.07</td>\n",
       "      <td>12268.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12181.33</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-25</td>\n",
       "      <td>1,342.54</td>\n",
       "      <td>2001-01-25</td>\n",
       "      <td>0.05878</td>\n",
       "      <td>-0.25720</td>\n",
       "      <td>0.830354</td>\n",
       "      <td>5.26</td>\n",
       "      <td>7.82</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>7.19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12383.96</td>\n",
       "      <td>12631.23</td>\n",
       "      <td>12584.00</td>\n",
       "      <td>12389.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12383.96</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-02-01</td>\n",
       "      <td>1,354.95</td>\n",
       "      <td>2001-02-01</td>\n",
       "      <td>0.05686</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.816765</td>\n",
       "      <td>5.19</td>\n",
       "      <td>7.55</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>7.04</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12527.35</td>\n",
       "      <td>12631.36</td>\n",
       "      <td>12719.22</td>\n",
       "      <td>12640.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12527.35</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>3,951.39</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>0.03802</td>\n",
       "      <td>-0.31372</td>\n",
       "      <td>0.873626</td>\n",
       "      <td>2.65</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.83</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41270.69</td>\n",
       "      <td>39855.04</td>\n",
       "      <td>39806.49</td>\n",
       "      <td>40399.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40450.95</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>2023-03-09</td>\n",
       "      <td>3,986.37</td>\n",
       "      <td>2023-03-09</td>\n",
       "      <td>-0.09704</td>\n",
       "      <td>-0.29014</td>\n",
       "      <td>0.941916</td>\n",
       "      <td>2.71</td>\n",
       "      <td>5.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.73</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39177.90</td>\n",
       "      <td>38592.37</td>\n",
       "      <td>38908.02</td>\n",
       "      <td>38264.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38379.18</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>3,891.93</td>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>0.06364</td>\n",
       "      <td>-0.15276</td>\n",
       "      <td>0.928371</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.59</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39576.30</td>\n",
       "      <td>38969.05</td>\n",
       "      <td>39674.70</td>\n",
       "      <td>39109.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38762.85</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>3,960.28</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>-0.18042</td>\n",
       "      <td>-0.18102</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.21</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4.53</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40080.50</td>\n",
       "      <td>39880.56</td>\n",
       "      <td>39318.14</td>\n",
       "      <td>39374.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39259.36</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>4,050.83</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>-0.08726</td>\n",
       "      <td>-0.17598</td>\n",
       "      <td>0.941916</td>\n",
       "      <td>3.04</td>\n",
       "      <td>6.70</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41548.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40708.47</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1160 rows × 613 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reported Date S&P 500 Weekly Close        date  headline_sentiment  \\\n",
       "0       2001-01-04             1,320.28  2001-01-04            -0.11490   \n",
       "1       2001-01-11             1,298.35  2001-01-11             0.20524   \n",
       "2       2001-01-18             1,318.55  2001-01-18            -0.12708   \n",
       "3       2001-01-25             1,342.54  2001-01-25             0.05878   \n",
       "4       2001-02-01             1,354.95  2001-02-01             0.05686   \n",
       "...            ...                  ...         ...                 ...   \n",
       "1155    2023-03-02             3,951.39  2023-03-02             0.03802   \n",
       "1156    2023-03-09             3,986.37  2023-03-09            -0.09704   \n",
       "1157    2023-03-16             3,891.93  2023-03-16             0.06364   \n",
       "1158    2023-03-23             3,960.28  2023-03-23            -0.18042   \n",
       "1159    2023-03-30             4,050.83  2023-03-30            -0.08726   \n",
       "\n",
       "      paragraph_sentiment  relevance  \\\n",
       "0                -0.06654   0.814249   \n",
       "1                 0.00962   0.867437   \n",
       "2                 0.03530   0.938922   \n",
       "3                -0.25720   0.830354   \n",
       "4                 0.00000   0.816765   \n",
       "...                   ...        ...   \n",
       "1155             -0.31372   0.873626   \n",
       "1156             -0.29014   0.941916   \n",
       "1157             -0.15276   0.928371   \n",
       "1158             -0.18102   0.800000   \n",
       "1159             -0.17598   0.941916   \n",
       "\n",
       "      ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread  \\\n",
       "0                                                  5.53                       \n",
       "1                                                  5.42                       \n",
       "2                                                  5.39                       \n",
       "3                                                  5.26                       \n",
       "4                                                  5.19                       \n",
       "...                                                 ...                       \n",
       "1155                                               2.65                       \n",
       "1156                                               2.71                       \n",
       "1157                                               3.00                       \n",
       "1158                                               3.21                       \n",
       "1159                                               3.04                       \n",
       "\n",
       "      ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread  \\\n",
       "0                                                  8.30                                  \n",
       "1                                                  8.09                                  \n",
       "2                                                  8.03                                  \n",
       "3                                                  7.82                                  \n",
       "4                                                  7.55                                  \n",
       "...                                                 ...                                  \n",
       "1155                                               5.92                                  \n",
       "1156                                               5.90                                  \n",
       "1157                                               6.70                                  \n",
       "1158                                               6.98                                  \n",
       "1159                                               6.70                                  \n",
       "\n",
       "      3-Month Commercial Paper Minus Federal Funds Rate  \\\n",
       "0                                                 -0.21   \n",
       "1                                                 -0.56   \n",
       "2                                                 -0.44   \n",
       "3                                                 -0.68   \n",
       "4                                                 -0.30   \n",
       "...                                                 ...   \n",
       "1155                                               0.27   \n",
       "1156                                                NaN   \n",
       "1157                                                NaN   \n",
       "1158                                               0.15   \n",
       "1159                                               0.22   \n",
       "\n",
       "      Moody's Seasoned Aaa Corporate Bond Yield  ...  \\\n",
       "0                                          7.09  ...   \n",
       "1                                          7.17  ...   \n",
       "2                                          7.09  ...   \n",
       "3                                          7.19  ...   \n",
       "4                                          7.04  ...   \n",
       "...                                         ...  ...   \n",
       "1155                                       4.83  ...   \n",
       "1156                                       4.73  ...   \n",
       "1157                                       4.59  ...   \n",
       "1158                                       4.53  ...   \n",
       "1159                                       4.48  ...   \n",
       "\n",
       "      Wilshire 5000 Price Index lag_4  Wilshire 5000 Price Index lag_5  \\\n",
       "0                                 NaN                              NaN   \n",
       "1                                 NaN                              NaN   \n",
       "2                                 NaN                              NaN   \n",
       "3                                 NaN                              NaN   \n",
       "4                                 NaN                              NaN   \n",
       "...                               ...                              ...   \n",
       "1155                              NaN                              NaN   \n",
       "1156                              NaN                              NaN   \n",
       "1157                              NaN                              NaN   \n",
       "1158                              NaN                              NaN   \n",
       "1159                              NaN                              NaN   \n",
       "\n",
       "      Wilshire 5000 Price Index lag_6  \\\n",
       "0                                 NaN   \n",
       "1                            11872.66   \n",
       "2                            12181.33   \n",
       "3                            12383.96   \n",
       "4                            12527.35   \n",
       "...                               ...   \n",
       "1155                         41270.69   \n",
       "1156                         39177.90   \n",
       "1157                         39576.30   \n",
       "1158                         40080.50   \n",
       "1159                         41548.10   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_1  \\\n",
       "0                                     12380.26   \n",
       "1                                     12064.50   \n",
       "2                                     12310.07   \n",
       "3                                     12631.23   \n",
       "4                                     12631.36   \n",
       "...                                        ...   \n",
       "1155                                  39855.04   \n",
       "1156                                  38592.37   \n",
       "1157                                  38969.05   \n",
       "1158                                  39880.56   \n",
       "1159                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_2  \\\n",
       "0                                     11763.92   \n",
       "1                                     11896.98   \n",
       "2                                     12268.09   \n",
       "3                                     12584.00   \n",
       "4                                     12719.22   \n",
       "...                                        ...   \n",
       "1155                                  39806.49   \n",
       "1156                                  38908.02   \n",
       "1157                                  39674.70   \n",
       "1158                                  39318.14   \n",
       "1159                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_3  \\\n",
       "0                                          NaN   \n",
       "1                                     11836.45   \n",
       "2                                          NaN   \n",
       "3                                     12389.91   \n",
       "4                                     12640.65   \n",
       "...                                        ...   \n",
       "1155                                  40399.86   \n",
       "1156                                  38264.73   \n",
       "1157                                  39109.85   \n",
       "1158                                  39374.94   \n",
       "1159                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_4  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "...                                        ...   \n",
       "1155                                       NaN   \n",
       "1156                                       NaN   \n",
       "1157                                       NaN   \n",
       "1158                                       NaN   \n",
       "1159                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_5  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "...                                        ...   \n",
       "1155                                       NaN   \n",
       "1156                                       NaN   \n",
       "1157                                       NaN   \n",
       "1158                                       NaN   \n",
       "1159                                       NaN   \n",
       "\n",
       "      Wilshire 5000 Full Cap Price Index lag_6  Sentiment  \n",
       "0                                          NaN    Bullish  \n",
       "1                                     11872.66    Bearish  \n",
       "2                                     12181.33    Neutral  \n",
       "3                                     12383.96    Bullish  \n",
       "4                                     12527.35    Bullish  \n",
       "...                                        ...        ...  \n",
       "1155                                  40450.95    Bearish  \n",
       "1156                                  38379.18    Bearish  \n",
       "1157                                  38762.85    Bearish  \n",
       "1158                                  39259.36    Bearish  \n",
       "1159                                  40708.47    Bearish  \n",
       "\n",
       "[1160 rows x 613 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overnight Repurchase Agreements: Total Securit...</td>\n",
       "      <td>57.155172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Overnight Repurchase Agreements: Total Securit...</td>\n",
       "      <td>55.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90-Day A2/P2 Nonfinancial Commercial Paper Int...</td>\n",
       "      <td>41.810345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-Year Treasury Bill Secondary Market Rate, Di...</td>\n",
       "      <td>39.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>37.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>37.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90-Day A2/P2 Nonfinancial Commercial Paper Int...</td>\n",
       "      <td>37.155172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>35.948276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>35.948276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1-Year Treasury Bill Secondary Market Rate, Di...</td>\n",
       "      <td>33.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1-Year Treasury Bill Secondary Market Rate, Di...</td>\n",
       "      <td>32.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1-Year Treasury Bill Secondary Market Rate, Di...</td>\n",
       "      <td>31.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1-Year Treasury Bill Secondary Market Rate, Di...</td>\n",
       "      <td>31.293103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90-Day A2/P2 Nonfinancial Commercial Paper Int...</td>\n",
       "      <td>31.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90-Day A2/P2 Nonfinancial Commercial Paper Int...</td>\n",
       "      <td>29.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90-Day A2/P2 Nonfinancial Commercial Paper Int...</td>\n",
       "      <td>28.793103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>28.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>28.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>28.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>28.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>26.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>90-Day AA Nonfinancial Commercial Paper Intere...</td>\n",
       "      <td>26.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Market Yield on U.S. Treasury Securities at 5-...</td>\n",
       "      <td>21.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5-Year, 5-Year Forward Inflation Expectation R...</td>\n",
       "      <td>21.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5-Year Breakeven Inflation Rate lag_3</td>\n",
       "      <td>21.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Market Yield on U.S. Treasury Securities at 10...</td>\n",
       "      <td>21.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10-Year Breakeven Inflation Rate lag_3</td>\n",
       "      <td>21.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3-Month Commercial Paper Minus Federal Funds R...</td>\n",
       "      <td>18.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>90-Day AA Financial Commercial Paper Interest ...</td>\n",
       "      <td>18.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>90-Day AA Financial Commercial Paper Interest ...</td>\n",
       "      <td>18.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4-Week Treasury Bill Secondary Market Rate, Di...</td>\n",
       "      <td>15.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Nikkei Stock Average, Nikkei 225 lag_3</td>\n",
       "      <td>15.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Discount Window Primary Credit Rate.1 lag_3</td>\n",
       "      <td>13.706897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Fitted Instantaneous Forward Rate 2 Years Henc...</td>\n",
       "      <td>13.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fitted Yield on a 10 Year Zero Coupon Bond lag_3</td>\n",
       "      <td>13.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Federal Funds Effective Rate lag_3</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Japanese Yen to U.S. Dollar Spot Exchange Rate...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Effective Federal Funds Rate lag_3</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Treasury Long-Term Average (Over 10 Years), In...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10-Year Treasury Constant Maturity Minus 2-Yea...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Mexican Pesos to U.S. Dollar Spot Exchange Rat...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6-Month Treasury Bill Secondary Market Rate, D...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Malaysian Ringgit to U.S. Dollar Spot Exchange...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10-Year Treasury Constant Maturity Minus Feder...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Brazilian Reals to U.S. Dollar Spot Exchange R...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Canadian Dollars to U.S. Dollar Spot Exchange ...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Indian Rupees to U.S. Dollar Spot Exchange Rat...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10-Year Treasury Constant Maturity Minus 3-Mon...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3-Month Treasury Bill Secondary Market Rate, D...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>South Korean Won to U.S. Dollar Spot Exchange ...</td>\n",
       "      <td>13.534483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          column_name  percent_missing\n",
       "0   Overnight Repurchase Agreements: Total Securit...        57.155172\n",
       "1   Overnight Repurchase Agreements: Total Securit...        55.862069\n",
       "2   90-Day A2/P2 Nonfinancial Commercial Paper Int...        41.810345\n",
       "3   1-Year Treasury Bill Secondary Market Rate, Di...        39.827586\n",
       "4   90-Day AA Nonfinancial Commercial Paper Intere...        37.586207\n",
       "5   90-Day AA Nonfinancial Commercial Paper Intere...        37.586207\n",
       "6   90-Day A2/P2 Nonfinancial Commercial Paper Int...        37.155172\n",
       "7   90-Day AA Nonfinancial Commercial Paper Intere...        35.948276\n",
       "8   90-Day AA Nonfinancial Commercial Paper Intere...        35.948276\n",
       "9   1-Year Treasury Bill Secondary Market Rate, Di...        33.275862\n",
       "10  1-Year Treasury Bill Secondary Market Rate, Di...        32.241379\n",
       "11  1-Year Treasury Bill Secondary Market Rate, Di...        31.724138\n",
       "12  1-Year Treasury Bill Secondary Market Rate, Di...        31.293103\n",
       "13  90-Day A2/P2 Nonfinancial Commercial Paper Int...        31.034483\n",
       "14  90-Day A2/P2 Nonfinancial Commercial Paper Int...        29.482759\n",
       "15  90-Day A2/P2 Nonfinancial Commercial Paper Int...        28.793103\n",
       "16  90-Day AA Nonfinancial Commercial Paper Intere...        28.620690\n",
       "17  90-Day AA Nonfinancial Commercial Paper Intere...        28.620690\n",
       "18  90-Day AA Nonfinancial Commercial Paper Intere...        28.534483\n",
       "19  90-Day AA Nonfinancial Commercial Paper Intere...        28.534483\n",
       "20  90-Day AA Nonfinancial Commercial Paper Intere...        26.896552\n",
       "21  90-Day AA Nonfinancial Commercial Paper Intere...        26.896552\n",
       "22  Market Yield on U.S. Treasury Securities at 5-...        21.206897\n",
       "23  5-Year, 5-Year Forward Inflation Expectation R...        21.206897\n",
       "24              5-Year Breakeven Inflation Rate lag_3        21.206897\n",
       "25  Market Yield on U.S. Treasury Securities at 10...        21.206897\n",
       "26             10-Year Breakeven Inflation Rate lag_3        21.206897\n",
       "27  3-Month Commercial Paper Minus Federal Funds R...        18.620690\n",
       "28  90-Day AA Financial Commercial Paper Interest ...        18.620690\n",
       "29  90-Day AA Financial Commercial Paper Interest ...        18.620690\n",
       "30  4-Week Treasury Bill Secondary Market Rate, Di...        15.862069\n",
       "31             Nikkei Stock Average, Nikkei 225 lag_3        15.689655\n",
       "32        Discount Window Primary Credit Rate.1 lag_3        13.706897\n",
       "33  Fitted Instantaneous Forward Rate 2 Years Henc...        13.620690\n",
       "34   Fitted Yield on a 10 Year Zero Coupon Bond lag_3        13.620690\n",
       "35                 Federal Funds Effective Rate lag_3        13.534483\n",
       "36  Japanese Yen to U.S. Dollar Spot Exchange Rate...        13.534483\n",
       "37                 Effective Federal Funds Rate lag_3        13.534483\n",
       "38  Treasury Long-Term Average (Over 10 Years), In...        13.534483\n",
       "39  10-Year Treasury Constant Maturity Minus 2-Yea...        13.534483\n",
       "40  Mexican Pesos to U.S. Dollar Spot Exchange Rat...        13.534483\n",
       "41  6-Month Treasury Bill Secondary Market Rate, D...        13.534483\n",
       "42  Malaysian Ringgit to U.S. Dollar Spot Exchange...        13.534483\n",
       "43  10-Year Treasury Constant Maturity Minus Feder...        13.534483\n",
       "44  Brazilian Reals to U.S. Dollar Spot Exchange R...        13.534483\n",
       "45  Canadian Dollars to U.S. Dollar Spot Exchange ...        13.534483\n",
       "46  Indian Rupees to U.S. Dollar Spot Exchange Rat...        13.534483\n",
       "47  10-Year Treasury Constant Maturity Minus 3-Mon...        13.534483\n",
       "48  3-Month Treasury Bill Secondary Market Rate, D...        13.534483\n",
       "49  South Korean Won to U.S. Dollar Spot Exchange ...        13.534483"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = final_data.isnull().sum() * 100 / len(final_data)\n",
    "missing_value_df_1 = pd.DataFrame({'column_name': final_data.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df_1.sort_values('percent_missing', inplace=True, ascending = False)\n",
    "missing_value_df_1.reset_index(drop = True, inplace = True)\n",
    "missing_value_df_1.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping high NA rows\n",
    "droppoorefeatures = pd.Series.tolist(missing_value_df_1[\"column_name\"][0:171])\n",
    "\n",
    "final_data.drop(droppoorefeatures, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reported Date',\n",
       " 'S&P 500 Weekly Close',\n",
       " 'date',\n",
       " 'headline_sentiment',\n",
       " 'paragraph_sentiment',\n",
       " 'relevance',\n",
       " 'ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread',\n",
       " 'ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread',\n",
       " '3-Month Commercial Paper Minus Federal Funds Rate',\n",
       " \"Moody's Seasoned Aaa Corporate Bond Yield\",\n",
       " \"Moody's Seasoned Baa Corporate Bond Yield\",\n",
       " 'Crude Oil Prices: Brent - Europe',\n",
       " 'Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate',\n",
       " 'Brazilian Reals to U.S. Dollar Spot Exchange Rate',\n",
       " 'Canadian Dollars to U.S. Dollar Spot Exchange Rate',\n",
       " 'Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate',\n",
       " 'Indian Rupees to U.S. Dollar Spot Exchange Rate',\n",
       " 'Japanese Yen to U.S. Dollar Spot Exchange Rate',\n",
       " 'South Korean Won to U.S. Dollar Spot Exchange Rate',\n",
       " 'Malaysian Ringgit to U.S. Dollar Spot Exchange Rate',\n",
       " 'Mexican Pesos to U.S. Dollar Spot Exchange Rate',\n",
       " 'Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed',\n",
       " 'Market Yield on U.S. Treasury Securities at 5-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed',\n",
       " 'Market Yield on U.S. Treasury Securities at 1-Year Constant Maturity, quoted on an Investment Basis',\n",
       " 'Henry Hub Natural Gas Spot Price',\n",
       " 'Kerosene-Type Jet Fuel Prices: U.S. Gulf Coast',\n",
       " 'Treasury Long-Term Average (Over 10 Years), Inflation-Indexed',\n",
       " 'Discount Window Primary Credit Rate',\n",
       " 'Bank Prime Loan Rate',\n",
       " '1-Year Treasury Bill Secondary Market Rate, Discount Basis',\n",
       " '3-Month Treasury Bill Secondary Market Rate, Discount Basis',\n",
       " '4-Week Treasury Bill Secondary Market Rate, Discount Basis',\n",
       " '6-Month Treasury Bill Secondary Market Rate, Discount Basis',\n",
       " 'Effective Federal Funds Rate',\n",
       " 'Daily Sterling Overnight Index Average (SONIA) Rate',\n",
       " 'Federal Funds Effective Rate',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate.1',\n",
       " '90-Day A2/P2 Nonfinancial Commercial Paper Interest Rate',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate.1',\n",
       " 'Overnight Repurchase Agreements: Total Securities Purchased by the Federal Reserve in the Temporary Open Market Operations',\n",
       " '10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity',\n",
       " '10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity',\n",
       " '10-Year Treasury Constant Maturity Minus Federal Funds Rate',\n",
       " '10-Year Breakeven Inflation Rate',\n",
       " '5-Year Breakeven Inflation Rate',\n",
       " '5-Year, 5-Year Forward Inflation Expectation Rate',\n",
       " 'Fitted Instantaneous Forward Rate 2 Years Hence',\n",
       " 'Fitted Yield on a 10 Year Zero Coupon Bond',\n",
       " 'Federal Funds Effective Rate.1',\n",
       " 'ECBDFR',\n",
       " 'Board of Governors of the Federal Reserve System (US)',\n",
       " 'Discount Window Primary Credit Rate.1',\n",
       " 'Economic Policy Uncertainty Index for United States',\n",
       " 'NBER based Recession Indicators for the United States from the Period following the Peak through the Trough',\n",
       " 'NBER based Recession Indicators for the United States from the Peak through the Trough',\n",
       " 'ICE BofA US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA US Corporate Index Effective Yield',\n",
       " 'ICE BofA AAA US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA AAA US Corporate Index Effective Yield',\n",
       " 'ICE BofA AA US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA AA US Corporate Index Effective Yield',\n",
       " 'ICE BofA Single-A US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA Single-A US Corporate Index Effective Yield',\n",
       " 'ICE BofA BBB US Corporate Index Option-Adjusted Spread',\n",
       " 'ICE BofA BBB US Corporate Index Effective Yield',\n",
       " 'ICE BofA 1-3 Year US Corporate Index Effective Yield',\n",
       " 'ICE BofA 7-10 Year US Corporate Index Effective Yield',\n",
       " 'ICE BofA US Corporate Index Total Return Index Value',\n",
       " 'ICE BofA US High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA US High Yield Index Effective Yield',\n",
       " 'ICE BofA US High Yield Index Semi-Annual Yield to Worst',\n",
       " 'ICE BofA BB US High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA BB US High Yield Index Effective Yield',\n",
       " 'ICE BofA Single-B US High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA Single-B US High Yield Index Effective Yield',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Effective Yield',\n",
       " 'ICE BofA Euro High Yield Index Effective Yield',\n",
       " 'ICE BofA Euro High Yield Index Option-Adjusted Spread',\n",
       " 'ICE BofA US High Yield Index Total Return Index Value',\n",
       " 'NASDAQ 100 Index',\n",
       " 'NASDAQ Composite Index',\n",
       " 'Nikkei Stock Average, Nikkei 225',\n",
       " 'CBOE Volatility Index: VIX',\n",
       " 'Wilshire 5000 Total Market Index',\n",
       " 'Wilshire 5000 Total Market Full Cap Index',\n",
       " 'Wilshire 5000 Price Index',\n",
       " 'Wilshire 5000 Full Cap Price Index',\n",
       " 'headline_sentiment lag_1',\n",
       " 'headline_sentiment lag_2',\n",
       " 'headline_sentiment lag_3',\n",
       " 'headline_sentiment lag_4',\n",
       " 'headline_sentiment lag_5',\n",
       " 'headline_sentiment lag_6',\n",
       " 'paragraph_sentiment lag_1',\n",
       " 'paragraph_sentiment lag_2',\n",
       " 'paragraph_sentiment lag_3',\n",
       " 'paragraph_sentiment lag_4',\n",
       " 'paragraph_sentiment lag_5',\n",
       " 'paragraph_sentiment lag_6',\n",
       " 'relevance lag_1',\n",
       " 'relevance lag_2',\n",
       " 'relevance lag_3',\n",
       " 'relevance lag_4',\n",
       " 'relevance lag_5',\n",
       " 'relevance lag_6',\n",
       " 'ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA Emerging Markets Corporate Plus Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA High Yield Emerging Markets Corporate Plus Index Option-Adjusted Spread lag_6',\n",
       " '3-Month Commercial Paper Minus Federal Funds Rate lag_1',\n",
       " '3-Month Commercial Paper Minus Federal Funds Rate lag_2',\n",
       " '3-Month Commercial Paper Minus Federal Funds Rate lag_3',\n",
       " '3-Month Commercial Paper Minus Federal Funds Rate lag_6',\n",
       " \"Moody's Seasoned Aaa Corporate Bond Yield lag_1\",\n",
       " \"Moody's Seasoned Aaa Corporate Bond Yield lag_2\",\n",
       " \"Moody's Seasoned Aaa Corporate Bond Yield lag_3\",\n",
       " \"Moody's Seasoned Aaa Corporate Bond Yield lag_6\",\n",
       " \"Moody's Seasoned Baa Corporate Bond Yield lag_1\",\n",
       " \"Moody's Seasoned Baa Corporate Bond Yield lag_2\",\n",
       " \"Moody's Seasoned Baa Corporate Bond Yield lag_3\",\n",
       " \"Moody's Seasoned Baa Corporate Bond Yield lag_6\",\n",
       " 'Crude Oil Prices: Brent - Europe lag_1',\n",
       " 'Crude Oil Prices: Brent - Europe lag_2',\n",
       " 'Crude Oil Prices: Brent - Europe lag_3',\n",
       " 'Crude Oil Prices: Brent - Europe lag_6',\n",
       " 'Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma lag_1',\n",
       " 'Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma lag_2',\n",
       " 'Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma lag_3',\n",
       " 'Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma lag_6',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate lag_1',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate lag_2',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate lag_3',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate lag_6',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate lag_1',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate lag_2',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate lag_3',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate lag_6',\n",
       " 'Brazilian Reals to U.S. Dollar Spot Exchange Rate lag_1',\n",
       " 'Brazilian Reals to U.S. Dollar Spot Exchange Rate lag_2',\n",
       " 'Brazilian Reals to U.S. Dollar Spot Exchange Rate lag_3',\n",
       " 'Brazilian Reals to U.S. Dollar Spot Exchange Rate lag_6',\n",
       " 'Canadian Dollars to U.S. Dollar Spot Exchange Rate lag_1',\n",
       " 'Canadian Dollars to U.S. Dollar Spot Exchange Rate lag_2',\n",
       " 'Canadian Dollars to U.S. Dollar Spot Exchange Rate lag_3',\n",
       " 'Canadian Dollars to U.S. Dollar Spot Exchange Rate lag_6',\n",
       " 'Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate lag_1',\n",
       " 'Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate lag_2',\n",
       " 'Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate lag_3',\n",
       " 'Chinese Yuan Renminbi to U.S. Dollar Spot Exchange Rate lag_6',\n",
       " 'Indian Rupees to U.S. Dollar Spot Exchange Rate lag_1',\n",
       " 'Indian Rupees to U.S. Dollar Spot Exchange Rate lag_2',\n",
       " 'Indian Rupees to U.S. Dollar Spot Exchange Rate lag_3',\n",
       " 'Indian Rupees to U.S. Dollar Spot Exchange Rate lag_6',\n",
       " 'Japanese Yen to U.S. Dollar Spot Exchange Rate lag_1',\n",
       " 'Japanese Yen to U.S. Dollar Spot Exchange Rate lag_2',\n",
       " 'Japanese Yen to U.S. Dollar Spot Exchange Rate lag_3',\n",
       " 'Japanese Yen to U.S. Dollar Spot Exchange Rate lag_6',\n",
       " 'South Korean Won to U.S. Dollar Spot Exchange Rate lag_1',\n",
       " 'South Korean Won to U.S. Dollar Spot Exchange Rate lag_2',\n",
       " 'South Korean Won to U.S. Dollar Spot Exchange Rate lag_3',\n",
       " 'South Korean Won to U.S. Dollar Spot Exchange Rate lag_6',\n",
       " 'Malaysian Ringgit to U.S. Dollar Spot Exchange Rate lag_1',\n",
       " 'Malaysian Ringgit to U.S. Dollar Spot Exchange Rate lag_2',\n",
       " 'Malaysian Ringgit to U.S. Dollar Spot Exchange Rate lag_3',\n",
       " 'Malaysian Ringgit to U.S. Dollar Spot Exchange Rate lag_6',\n",
       " 'Mexican Pesos to U.S. Dollar Spot Exchange Rate lag_1',\n",
       " 'Mexican Pesos to U.S. Dollar Spot Exchange Rate lag_2',\n",
       " 'Mexican Pesos to U.S. Dollar Spot Exchange Rate lag_3',\n",
       " 'Mexican Pesos to U.S. Dollar Spot Exchange Rate lag_6',\n",
       " 'Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed lag_1',\n",
       " 'Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed lag_2',\n",
       " 'Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed lag_3',\n",
       " 'Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed lag_6',\n",
       " 'Market Yield on U.S. Treasury Securities at 5-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed lag_1',\n",
       " 'Market Yield on U.S. Treasury Securities at 5-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed lag_2',\n",
       " 'Market Yield on U.S. Treasury Securities at 5-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed lag_3',\n",
       " 'Market Yield on U.S. Treasury Securities at 5-Year Constant Maturity, Quoted on an Investment Basis, Inflation-Indexed lag_6',\n",
       " 'Market Yield on U.S. Treasury Securities at 1-Year Constant Maturity, quoted on an Investment Basis lag_1',\n",
       " 'Market Yield on U.S. Treasury Securities at 1-Year Constant Maturity, quoted on an Investment Basis lag_2',\n",
       " 'Market Yield on U.S. Treasury Securities at 1-Year Constant Maturity, quoted on an Investment Basis lag_3',\n",
       " 'Market Yield on U.S. Treasury Securities at 1-Year Constant Maturity, quoted on an Investment Basis lag_6',\n",
       " 'Henry Hub Natural Gas Spot Price lag_1',\n",
       " 'Henry Hub Natural Gas Spot Price lag_2',\n",
       " 'Henry Hub Natural Gas Spot Price lag_3',\n",
       " 'Henry Hub Natural Gas Spot Price lag_6',\n",
       " 'Kerosene-Type Jet Fuel Prices: U.S. Gulf Coast lag_1',\n",
       " 'Kerosene-Type Jet Fuel Prices: U.S. Gulf Coast lag_2',\n",
       " 'Kerosene-Type Jet Fuel Prices: U.S. Gulf Coast lag_3',\n",
       " 'Kerosene-Type Jet Fuel Prices: U.S. Gulf Coast lag_6',\n",
       " 'Treasury Long-Term Average (Over 10 Years), Inflation-Indexed lag_1',\n",
       " 'Treasury Long-Term Average (Over 10 Years), Inflation-Indexed lag_2',\n",
       " 'Treasury Long-Term Average (Over 10 Years), Inflation-Indexed lag_3',\n",
       " 'Treasury Long-Term Average (Over 10 Years), Inflation-Indexed lag_6',\n",
       " 'Discount Window Primary Credit Rate lag_1',\n",
       " 'Discount Window Primary Credit Rate lag_2',\n",
       " 'Discount Window Primary Credit Rate lag_3',\n",
       " 'Discount Window Primary Credit Rate lag_6',\n",
       " 'Bank Prime Loan Rate lag_1',\n",
       " 'Bank Prime Loan Rate lag_2',\n",
       " 'Bank Prime Loan Rate lag_3',\n",
       " 'Bank Prime Loan Rate lag_6',\n",
       " '1-Year Treasury Bill Secondary Market Rate, Discount Basis lag_1',\n",
       " '1-Year Treasury Bill Secondary Market Rate, Discount Basis lag_2',\n",
       " '1-Year Treasury Bill Secondary Market Rate, Discount Basis lag_3',\n",
       " '1-Year Treasury Bill Secondary Market Rate, Discount Basis lag_6',\n",
       " '3-Month Treasury Bill Secondary Market Rate, Discount Basis lag_1',\n",
       " '3-Month Treasury Bill Secondary Market Rate, Discount Basis lag_2',\n",
       " '3-Month Treasury Bill Secondary Market Rate, Discount Basis lag_3',\n",
       " '3-Month Treasury Bill Secondary Market Rate, Discount Basis lag_6',\n",
       " '4-Week Treasury Bill Secondary Market Rate, Discount Basis lag_1',\n",
       " '4-Week Treasury Bill Secondary Market Rate, Discount Basis lag_2',\n",
       " '4-Week Treasury Bill Secondary Market Rate, Discount Basis lag_3',\n",
       " '4-Week Treasury Bill Secondary Market Rate, Discount Basis lag_6',\n",
       " '6-Month Treasury Bill Secondary Market Rate, Discount Basis lag_1',\n",
       " '6-Month Treasury Bill Secondary Market Rate, Discount Basis lag_2',\n",
       " '6-Month Treasury Bill Secondary Market Rate, Discount Basis lag_3',\n",
       " '6-Month Treasury Bill Secondary Market Rate, Discount Basis lag_6',\n",
       " 'Effective Federal Funds Rate lag_1',\n",
       " 'Effective Federal Funds Rate lag_2',\n",
       " 'Effective Federal Funds Rate lag_3',\n",
       " 'Effective Federal Funds Rate lag_6',\n",
       " 'Daily Sterling Overnight Index Average (SONIA) Rate lag_1',\n",
       " 'Daily Sterling Overnight Index Average (SONIA) Rate lag_2',\n",
       " 'Daily Sterling Overnight Index Average (SONIA) Rate lag_3',\n",
       " 'Daily Sterling Overnight Index Average (SONIA) Rate lag_6',\n",
       " 'Federal Funds Effective Rate lag_1',\n",
       " 'Federal Funds Effective Rate lag_2',\n",
       " 'Federal Funds Effective Rate lag_3',\n",
       " 'Federal Funds Effective Rate lag_6',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate.1 lag_1',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate.1 lag_2',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate.1 lag_3',\n",
       " '90-Day AA Financial Commercial Paper Interest Rate.1 lag_6',\n",
       " '90-Day A2/P2 Nonfinancial Commercial Paper Interest Rate lag_1',\n",
       " '90-Day A2/P2 Nonfinancial Commercial Paper Interest Rate lag_2',\n",
       " '90-Day A2/P2 Nonfinancial Commercial Paper Interest Rate lag_3',\n",
       " '90-Day A2/P2 Nonfinancial Commercial Paper Interest Rate lag_6',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate.1 lag_1',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate.1 lag_2',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate.1 lag_3',\n",
       " '90-Day AA Nonfinancial Commercial Paper Interest Rate.1 lag_6',\n",
       " 'Overnight Repurchase Agreements: Total Securities Purchased by the Federal Reserve in the Temporary Open Market Operations lag_1',\n",
       " '10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity lag_1',\n",
       " '10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity lag_2',\n",
       " '10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity lag_3',\n",
       " '10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity lag_6',\n",
       " '10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity lag_1',\n",
       " '10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity lag_2',\n",
       " '10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity lag_3',\n",
       " '10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity lag_6',\n",
       " '10-Year Treasury Constant Maturity Minus Federal Funds Rate lag_1',\n",
       " '10-Year Treasury Constant Maturity Minus Federal Funds Rate lag_2',\n",
       " '10-Year Treasury Constant Maturity Minus Federal Funds Rate lag_3',\n",
       " '10-Year Treasury Constant Maturity Minus Federal Funds Rate lag_6',\n",
       " '10-Year Breakeven Inflation Rate lag_1',\n",
       " '10-Year Breakeven Inflation Rate lag_2',\n",
       " '10-Year Breakeven Inflation Rate lag_3',\n",
       " '10-Year Breakeven Inflation Rate lag_6',\n",
       " '5-Year Breakeven Inflation Rate lag_1',\n",
       " '5-Year Breakeven Inflation Rate lag_2',\n",
       " '5-Year Breakeven Inflation Rate lag_3',\n",
       " '5-Year Breakeven Inflation Rate lag_6',\n",
       " '5-Year, 5-Year Forward Inflation Expectation Rate lag_1',\n",
       " '5-Year, 5-Year Forward Inflation Expectation Rate lag_2',\n",
       " '5-Year, 5-Year Forward Inflation Expectation Rate lag_3',\n",
       " '5-Year, 5-Year Forward Inflation Expectation Rate lag_6',\n",
       " 'Fitted Instantaneous Forward Rate 2 Years Hence lag_1',\n",
       " 'Fitted Instantaneous Forward Rate 2 Years Hence lag_2',\n",
       " 'Fitted Instantaneous Forward Rate 2 Years Hence lag_3',\n",
       " 'Fitted Instantaneous Forward Rate 2 Years Hence lag_6',\n",
       " 'Fitted Yield on a 10 Year Zero Coupon Bond lag_1',\n",
       " 'Fitted Yield on a 10 Year Zero Coupon Bond lag_2',\n",
       " 'Fitted Yield on a 10 Year Zero Coupon Bond lag_3',\n",
       " 'Fitted Yield on a 10 Year Zero Coupon Bond lag_6',\n",
       " 'Federal Funds Effective Rate.1 lag_1',\n",
       " 'Federal Funds Effective Rate.1 lag_2',\n",
       " 'Federal Funds Effective Rate.1 lag_3',\n",
       " 'Federal Funds Effective Rate.1 lag_6',\n",
       " 'ECBDFR lag_1',\n",
       " 'ECBDFR lag_2',\n",
       " 'ECBDFR lag_3',\n",
       " 'ECBDFR lag_6',\n",
       " 'Board of Governors of the Federal Reserve System (US) lag_1',\n",
       " 'Board of Governors of the Federal Reserve System (US) lag_2',\n",
       " 'Board of Governors of the Federal Reserve System (US) lag_3',\n",
       " 'Board of Governors of the Federal Reserve System (US) lag_6',\n",
       " 'Discount Window Primary Credit Rate.1 lag_1',\n",
       " 'Discount Window Primary Credit Rate.1 lag_2',\n",
       " 'Discount Window Primary Credit Rate.1 lag_3',\n",
       " 'Discount Window Primary Credit Rate.1 lag_6',\n",
       " 'Economic Policy Uncertainty Index for United States lag_1',\n",
       " 'Economic Policy Uncertainty Index for United States lag_2',\n",
       " 'Economic Policy Uncertainty Index for United States lag_3',\n",
       " 'Economic Policy Uncertainty Index for United States lag_6',\n",
       " 'NBER based Recession Indicators for the United States from the Period following the Peak through the Trough lag_1',\n",
       " 'NBER based Recession Indicators for the United States from the Period following the Peak through the Trough lag_2',\n",
       " 'NBER based Recession Indicators for the United States from the Period following the Peak through the Trough lag_3',\n",
       " 'NBER based Recession Indicators for the United States from the Period following the Peak through the Trough lag_6',\n",
       " 'NBER based Recession Indicators for the United States from the Peak through the Trough lag_1',\n",
       " 'NBER based Recession Indicators for the United States from the Peak through the Trough lag_2',\n",
       " 'NBER based Recession Indicators for the United States from the Peak through the Trough lag_3',\n",
       " 'NBER based Recession Indicators for the United States from the Peak through the Trough lag_6',\n",
       " 'ICE BofA US Corporate Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA US Corporate Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA US Corporate Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA US Corporate Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA US Corporate Index Effective Yield lag_1',\n",
       " 'ICE BofA US Corporate Index Effective Yield lag_2',\n",
       " 'ICE BofA US Corporate Index Effective Yield lag_3',\n",
       " 'ICE BofA US Corporate Index Effective Yield lag_6',\n",
       " 'ICE BofA AAA US Corporate Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA AAA US Corporate Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA AAA US Corporate Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA AAA US Corporate Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA AAA US Corporate Index Effective Yield lag_1',\n",
       " 'ICE BofA AAA US Corporate Index Effective Yield lag_2',\n",
       " 'ICE BofA AAA US Corporate Index Effective Yield lag_3',\n",
       " 'ICE BofA AAA US Corporate Index Effective Yield lag_6',\n",
       " 'ICE BofA AA US Corporate Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA AA US Corporate Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA AA US Corporate Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA AA US Corporate Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA AA US Corporate Index Effective Yield lag_1',\n",
       " 'ICE BofA AA US Corporate Index Effective Yield lag_2',\n",
       " 'ICE BofA AA US Corporate Index Effective Yield lag_3',\n",
       " 'ICE BofA AA US Corporate Index Effective Yield lag_6',\n",
       " 'ICE BofA Single-A US Corporate Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA Single-A US Corporate Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA Single-A US Corporate Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA Single-A US Corporate Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA Single-A US Corporate Index Effective Yield lag_1',\n",
       " 'ICE BofA Single-A US Corporate Index Effective Yield lag_2',\n",
       " 'ICE BofA Single-A US Corporate Index Effective Yield lag_3',\n",
       " 'ICE BofA Single-A US Corporate Index Effective Yield lag_6',\n",
       " 'ICE BofA BBB US Corporate Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA BBB US Corporate Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA BBB US Corporate Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA BBB US Corporate Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA BBB US Corporate Index Effective Yield lag_1',\n",
       " 'ICE BofA BBB US Corporate Index Effective Yield lag_2',\n",
       " 'ICE BofA BBB US Corporate Index Effective Yield lag_3',\n",
       " 'ICE BofA BBB US Corporate Index Effective Yield lag_6',\n",
       " 'ICE BofA 1-3 Year US Corporate Index Effective Yield lag_1',\n",
       " 'ICE BofA 1-3 Year US Corporate Index Effective Yield lag_2',\n",
       " 'ICE BofA 1-3 Year US Corporate Index Effective Yield lag_3',\n",
       " 'ICE BofA 1-3 Year US Corporate Index Effective Yield lag_6',\n",
       " 'ICE BofA 7-10 Year US Corporate Index Effective Yield lag_1',\n",
       " 'ICE BofA 7-10 Year US Corporate Index Effective Yield lag_2',\n",
       " 'ICE BofA 7-10 Year US Corporate Index Effective Yield lag_3',\n",
       " 'ICE BofA 7-10 Year US Corporate Index Effective Yield lag_6',\n",
       " 'ICE BofA US Corporate Index Total Return Index Value lag_1',\n",
       " 'ICE BofA US Corporate Index Total Return Index Value lag_2',\n",
       " 'ICE BofA US Corporate Index Total Return Index Value lag_3',\n",
       " 'ICE BofA US Corporate Index Total Return Index Value lag_6',\n",
       " 'ICE BofA US High Yield Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA US High Yield Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA US High Yield Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA US High Yield Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA US High Yield Index Effective Yield lag_1',\n",
       " 'ICE BofA US High Yield Index Effective Yield lag_2',\n",
       " 'ICE BofA US High Yield Index Effective Yield lag_3',\n",
       " 'ICE BofA US High Yield Index Effective Yield lag_6',\n",
       " 'ICE BofA US High Yield Index Semi-Annual Yield to Worst lag_1',\n",
       " 'ICE BofA US High Yield Index Semi-Annual Yield to Worst lag_2',\n",
       " 'ICE BofA US High Yield Index Semi-Annual Yield to Worst lag_3',\n",
       " 'ICE BofA US High Yield Index Semi-Annual Yield to Worst lag_6',\n",
       " 'ICE BofA BB US High Yield Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA BB US High Yield Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA BB US High Yield Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA BB US High Yield Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA BB US High Yield Index Effective Yield lag_1',\n",
       " 'ICE BofA BB US High Yield Index Effective Yield lag_2',\n",
       " 'ICE BofA BB US High Yield Index Effective Yield lag_3',\n",
       " 'ICE BofA BB US High Yield Index Effective Yield lag_6',\n",
       " 'ICE BofA Single-B US High Yield Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA Single-B US High Yield Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA Single-B US High Yield Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA Single-B US High Yield Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA Single-B US High Yield Index Effective Yield lag_1',\n",
       " 'ICE BofA Single-B US High Yield Index Effective Yield lag_2',\n",
       " 'ICE BofA Single-B US High Yield Index Effective Yield lag_3',\n",
       " 'ICE BofA Single-B US High Yield Index Effective Yield lag_6',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Effective Yield lag_1',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Effective Yield lag_2',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Effective Yield lag_3',\n",
       " 'ICE BofA CCC & Lower US High Yield Index Effective Yield lag_6',\n",
       " 'ICE BofA Euro High Yield Index Effective Yield lag_1',\n",
       " 'ICE BofA Euro High Yield Index Effective Yield lag_2',\n",
       " 'ICE BofA Euro High Yield Index Effective Yield lag_3',\n",
       " 'ICE BofA Euro High Yield Index Effective Yield lag_6',\n",
       " 'ICE BofA Euro High Yield Index Option-Adjusted Spread lag_1',\n",
       " 'ICE BofA Euro High Yield Index Option-Adjusted Spread lag_2',\n",
       " 'ICE BofA Euro High Yield Index Option-Adjusted Spread lag_3',\n",
       " 'ICE BofA Euro High Yield Index Option-Adjusted Spread lag_6',\n",
       " 'ICE BofA US High Yield Index Total Return Index Value lag_1',\n",
       " 'ICE BofA US High Yield Index Total Return Index Value lag_2',\n",
       " 'ICE BofA US High Yield Index Total Return Index Value lag_3',\n",
       " 'ICE BofA US High Yield Index Total Return Index Value lag_6',\n",
       " 'NASDAQ 100 Index lag_1',\n",
       " 'NASDAQ 100 Index lag_2',\n",
       " 'NASDAQ 100 Index lag_3',\n",
       " 'NASDAQ 100 Index lag_6',\n",
       " 'NASDAQ Composite Index lag_1',\n",
       " 'NASDAQ Composite Index lag_2',\n",
       " 'NASDAQ Composite Index lag_3',\n",
       " 'NASDAQ Composite Index lag_6',\n",
       " 'Nikkei Stock Average, Nikkei 225 lag_1',\n",
       " 'Nikkei Stock Average, Nikkei 225 lag_2',\n",
       " 'Nikkei Stock Average, Nikkei 225 lag_3',\n",
       " 'Nikkei Stock Average, Nikkei 225 lag_6',\n",
       " 'CBOE Volatility Index: VIX lag_1',\n",
       " 'CBOE Volatility Index: VIX lag_2',\n",
       " 'CBOE Volatility Index: VIX lag_3',\n",
       " 'CBOE Volatility Index: VIX lag_6',\n",
       " 'Wilshire 5000 Total Market Index lag_1',\n",
       " 'Wilshire 5000 Total Market Index lag_2',\n",
       " 'Wilshire 5000 Total Market Index lag_3',\n",
       " 'Wilshire 5000 Total Market Index lag_6',\n",
       " 'Wilshire 5000 Total Market Full Cap Index lag_1',\n",
       " 'Wilshire 5000 Total Market Full Cap Index lag_2',\n",
       " 'Wilshire 5000 Total Market Full Cap Index lag_3',\n",
       " 'Wilshire 5000 Total Market Full Cap Index lag_6',\n",
       " 'Wilshire 5000 Price Index lag_1',\n",
       " 'Wilshire 5000 Price Index lag_2',\n",
       " 'Wilshire 5000 Price Index lag_3',\n",
       " 'Wilshire 5000 Price Index lag_6',\n",
       " 'Wilshire 5000 Full Cap Price Index lag_1',\n",
       " 'Wilshire 5000 Full Cap Price Index lag_2',\n",
       " 'Wilshire 5000 Full Cap Price Index lag_3',\n",
       " 'Wilshire 5000 Full Cap Price Index lag_6',\n",
       " 'Sentiment']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before test train split. Need to create variables for empirical irrelgularities and lagged sentiment\n",
    "#Creating recency variable\n",
    "\n",
    "#Bascially acts as a damping factor for the sentiment. The more recent the article, the more weight it has\n",
    "final_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data[\"paragraph_sentiment lag_1::recency_bias\"] = final_data[\"paragraph_sentiment lag_1\"] * 0.9\n",
    "final_data[\"paragraph_sentiment lag_2::recency_bias\"] = final_data[\"paragraph_sentiment lag_2\"] * 0.4\n",
    "final_data[\"paragraph_sentiment lag_3::recency_bias\"] = final_data[\"paragraph_sentiment lag_3\"] * 0.32\n",
    "final_data[\"paragraph_sentiment lag_4::recency_bias\"] = final_data[\"paragraph_sentiment lag_4\"] * 0.28\n",
    "final_data[\"paragraph_sentiment lag_5::recency_bias\"] = final_data[\"paragraph_sentiment lag_5\"] * 0.23\n",
    "final_data[\"paragraph_sentiment lag_6::recency_bias\"] = final_data[\"paragraph_sentiment lag_6\"] * 0.20\n",
    "\n",
    "final_data[\"headline_sentiment lag_1::recency_bias\"] = final_data[\"headline_sentiment lag_1\"] * 0.9\n",
    "final_data[\"headline_sentiment lag_2::recency_bias\"] = final_data[\"headline_sentiment lag_2\"] * 0.4\n",
    "final_data[\"headline_sentiment lag_3::recency_bias\"] = final_data[\"headline_sentiment lag_3\"] * 0.32 \n",
    "final_data[\"headline_sentiment lag_4::recency_bias\"] = final_data[\"headline_sentiment lag_4\"] * 0.28\n",
    "final_data[\"headline_sentiment lag_5::recency_bias\"] = final_data[\"headline_sentiment lag_5\"] * 0.23\n",
    "final_data[\"headline_sentiment lag_6::recency_bias\"] = final_data[\"headline_sentiment lag_6\"] * 0.20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rahul\\OneDrive\\Desktop\\Education\\Year 3\\Winter Sem\\ECO481\\Final Project\\Final_model_generation.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Desktop/Education/Year%203/Winter%20Sem/ECO481/Final%20Project/Final_model_generation.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Desktop/Education/Year%203/Winter%20Sem/ECO481/Final%20Project/Final_model_generation.ipynb#X54sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m df[column_name] \u001b[39m*\u001b[39m \u001b[39m0.8\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Desktop/Education/Year%203/Winter%20Sem/ECO481/Final%20Project/Final_model_generation.ipynb#X54sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m final_data[\u001b[39m\"\u001b[39m\u001b[39mparagraph_sentiment::assymetric_processing\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m final_data\u001b[39m.\u001b[39mapply(assymetric_processing(df \u001b[39m=\u001b[39;49m final_data, column_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mparagraph_sentiment\u001b[39;49m\u001b[39m\"\u001b[39;49m), axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\rahul\\OneDrive\\Desktop\\Education\\Year 3\\Winter Sem\\ECO481\\Final Project\\Final_model_generation.ipynb Cell 28\u001b[0m in \u001b[0;36massymetric_processing\u001b[1;34m(df, column_name)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Desktop/Education/Year%203/Winter%20Sem/ECO481/Final%20Project/Final_model_generation.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39massymetric_processing\u001b[39m(df, column_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mparagraph_sentiment\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Desktop/Education/Year%203/Winter%20Sem/ECO481/Final%20Project/Final_model_generation.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m df[column_name] \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Desktop/Education/Year%203/Winter%20Sem/ECO481/Final%20Project/Final_model_generation.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m df[column_name] \u001b[39m*\u001b[39m \u001b[39m1.2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Desktop/Education/Year%203/Winter%20Sem/ECO481/Final%20Project/Final_model_generation.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1526\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1528\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1530\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# Asymmmetric processing of bad news. If the sentiment is positive, we want to amplify it. If it is negative, we want to dampen \n",
    "def assymetric_processing(df, column_name = \"paragraph_sentiment\"):\n",
    "    if df[column_name] > 0:\n",
    "        return df[column_name] * 1.2\n",
    "    else:\n",
    "        return df[column_name] * 0.8\n",
    "\n",
    "final_data[\"paragraph_sentiment::assymetric_processing\"] = final_data.apply(assymetric_processing(df = final_data, column_name=\"paragraph_sentiment\"), axis = 1)\n",
    "#final_data[\"headline_sentiment::assymetric_processing\"] = final_data.apply(assymetric_processing(df = final_data, column_name=\"headline_sentiment\"), axis = 1)\n",
    "#fina\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\2270248191.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] < 0] = final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] < 0] * 0.8\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\2270248191.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] >= 0] = final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] >= 0] * 1.2\n"
     ]
    }
   ],
   "source": [
    "final_data[\"headline_sentiment::assymetric_processing\"] = final_data[\"headline_sentiment\"]\n",
    "final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] < 0] = final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] < 0] * 0.8\n",
    "final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] >= 0] = final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] >= 0] * 1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\2417446387.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data[\"paragraph_sentiment::assymetric_processing\"][final_data[\"paragraph_sentiment\"] < 0] = final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] < 0] * 0.8\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_50460\\2417446387.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data[\"paragraph_sentiment::assymetric_processing\"][final_data[\"paragraph_sentiment\"] >= 0] = final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] >= 0] * 1.2\n"
     ]
    }
   ],
   "source": [
    "final_data[\"paragraph_sentiment::assymetric_processing\"] = final_data[\"paragraph_sentiment\"]\n",
    "final_data[\"paragraph_sentiment::assymetric_processing\"][final_data[\"paragraph_sentiment\"] < 0] = final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] < 0] * 0.8\n",
    "final_data[\"paragraph_sentiment::assymetric_processing\"][final_data[\"paragraph_sentiment\"] >= 0] = final_data[\"headline_sentiment::assymetric_processing\"][final_data[\"headline_sentiment\"] >= 0] * 1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsv_model(df):\n",
    "    list_of_nasdaq_100 = [df['NASDAQ 100 Index lag_3'], df['NASDAQ 100 Index lag_2'],df['NASDAQ 100 Index lag_1'], df['NASDAQ 100 Index']]\n",
    "    if sorted(list_of_nasdaq_100) == list_of_nasdaq_100:\n",
    "        return \"Momentum\"\n",
    "    elif sorted(list_of_nasdaq_100, reverse = True) == list_of_nasdaq_100:\n",
    "        return \"Momentum\"\n",
    "    elif list_of_nasdaq_100[0] < list_of_nasdaq_100[1]:\n",
    "        if list_of_nasdaq_100[1] > list_of_nasdaq_100[2]:\n",
    "            if list_of_nasdaq_100[2] < list_of_nasdaq_100[3]:\n",
    "                return \"Reversal\"\n",
    "            else: \n",
    "                return \"Random\"\n",
    "        else:\n",
    "            return \"Random\"\n",
    "        \n",
    "    elif list_of_nasdaq_100[0] > list_of_nasdaq_100[1]:\n",
    "        if list_of_nasdaq_100[1] < list_of_nasdaq_100[2]:\n",
    "            if list_of_nasdaq_100[2] > list_of_nasdaq_100[3]:\n",
    "                return \"Reversal\"\n",
    "            else:\n",
    "                return \"Random\"\n",
    "        else:\n",
    "            return \"Random\"\n",
    "        \n",
    "    else:\n",
    "        return \"Random\"\n",
    "\n",
    "final_data[\"BSV_irregularity\"] = final_data.apply(bsv_model, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT into train and test  1000 data point there 70-30 split is ideal\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1006809296)\n",
    "x_train, x_test, y_train, y_test = train_test_split(final_data.drop([\"date\", \"Sentiment\", \"Reported Date\"], axis=1), final_data[\"Sentiment\"], test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv(\"x_train.csv\")\n",
    "x_test.to_csv(\"x_test.csv\")\n",
    "y_train.to_csv(\"y_train.csv\")\n",
    "y_test.to_csv(\"y_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
